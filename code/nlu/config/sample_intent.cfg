[project]
project_root_path = path_to_the_project_root

[data]
arabic_data_path = ./data/Arabic
french_data_path = ./data/French
turkish_data_path = ./data/Turkish
english_data_path = ./data/English
parallel_dic_path = ./data/parallel_dic.json

[experiment]
task = intent
train_languages = {"Arabic": "random1.0"}
val_languages = {"Arabic": "random1.0"}
test_languages = {"Arabic": "random1.0"}
model_name = xlm-roberta-base
seed = 1
batch_size = 128
process_mode = user
context_window = 3
output_dir = ./output/example_intent
learning_rate = 2e-5
weight_decay = 0.1
max_context_char_length = 150
save_total_limit = 1
eval_and_save_steps = 500
max_training_steps = 20000
early_stopping_patience = 2
